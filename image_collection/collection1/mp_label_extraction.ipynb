{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Extraction: Amazon Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies for system configuration\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# import dependencies for collecting images\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach: Image Extraction\n",
    "\n",
    "+ Loading Dataset of amazon urls\n",
    "+ Extracting images per url \n",
    "+ Downloading mobile phone images with created folder\n",
    "+ Storing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.com.be/-/en/s?i=electronics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.com.be/-/en/s?i=electronics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.com.be/-/en/s?i=electronics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.com.be/-/en/s?i=electronics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.com.be/-/en/s?i=electronics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links\n",
       "0  https://www.amazon.com.be/-/en/s?i=electronics...\n",
       "1  https://www.amazon.com.be/-/en/s?i=electronics...\n",
       "2  https://www.amazon.com.be/-/en/s?i=electronics...\n",
       "3  https://www.amazon.com.be/-/en/s?i=electronics...\n",
       "4  https://www.amazon.com.be/-/en/s?i=electronics..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the amazon weblink dataset\n",
    "weblink_file = \"links_page1.csv\"\n",
    "amazon_ds = pd.read_csv(weblink_file)\n",
    "amazon_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extracting from URL (P1): Testcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Setup WebDriver\n",
    "+ Extracting labels from amazon webpage\n",
    "+ Storing labels in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies for extracting image content from amazon webpage\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Webdriver for Edge Browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "\n",
    "# Set up Browser service \n",
    "edgedriver_path = \"D:\\\\Data_Engineering\\\\data_extraction\\\\msedgedriver.exe\"\n",
    "service = Service(executable_path=edgedriver_path)\n",
    "driver = webdriver.Edge(service=service, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Case 1: Amazon with 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon URL 1: 24 items (extracted successfully) \n",
      "Amazon URL 2: 24 items (extracted successfully) \n",
      "Amazon URL 3: 24 items (extracted successfully) \n",
      "Amazon URL 4: 24 items (extracted successfully) \n",
      "Amazon URL 5: 24 items (extracted successfully) \n",
      "Amazon URL 6: 3 items (extracted successfully) \n",
      "Amazon URL 7: 3 items (extracted successfully) \n",
      "Amazon URL 8: 2 items (extracted successfully) \n",
      "Amazon URL 9: 12 items (extracted successfully) \n",
      "Amazon URL 10: 3 items (extracted successfully) \n",
      "Extraction Successful. Number of Items: 143\n"
     ]
    }
   ],
   "source": [
    "# Test case 1: 1 amazon link \n",
    "amazon_link = amazon_ds[\"links\"].values[0]\n",
    "\n",
    "def extract_labels(webdriver, link) -> list:\n",
    "    webdriver.get(link)\n",
    "    time.sleep(5)\n",
    "\n",
    "    product_titles = driver.execute_script(\"\"\" \n",
    "        var h2_selector = \"h2.a-size-base-plus.a-spacing-none.a-color-base.a-text-normal\";\n",
    "        var titles = [];\n",
    "        var elements = document.querySelectorAll(h2_selector);\n",
    "        elements.forEach(function(element){\n",
    "            titles.push(element.innerText);                                       \n",
    "        });\n",
    "        return titles\n",
    "    \"\"\")\n",
    "\n",
    "    return product_titles\n",
    "\n",
    "# Test case 2: 3 amazon links \n",
    "amazon_links = amazon_ds[\"links\"].values[0:10]\n",
    "item_title_lst = []\n",
    "item_tot = 0\n",
    "for i, link in enumerate(amazon_links): \n",
    "    # Extract the product titles from each link + take the size of each sequence\n",
    "    text_sequence = extract_labels(webdriver=driver, link=link)\n",
    "    seq_len = len(text_sequence)\n",
    "\n",
    "    # Store text sequence in list of all item titles\n",
    "    item_title_lst.append(text_sequence)\n",
    "    print(f\"Amazon URL {i + 1}: {seq_len} items (extracted successfully) \")\n",
    "    item_tot += seq_len\n",
    "print(f\"Extraction Successful. Number of Items: {item_tot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Samsung Galaxy SM-G780GZWDEUB 6.5 Inch Dual SIM Hybrid 4G USB Type-C 6GB 128GB 4500mAh Mint',\n",
       "       'Samsung Galaxy S20 FE 5G Unlocked Blue',\n",
       "       'SAMSUNG A135F/DSN Galaxy A13 Dual SIM (6.6 inches - 4/128GB) Black',\n",
       "       'Samsung SM-A156B Galaxy A15 Dual SIM 5G 4GB RAM 128GB Blue Black EU',\n",
       "       'Samsung Galaxy S20 FE 5G 6GB/128GB Purple (Lavender) Dual SIM G781B'],\n",
       "      dtype='<U192')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_titles = np.array([item for title_seq in item_title_lst for item in title_seq])\n",
    "item_titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction P2: Full Page (Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon URL 0: 24 items (extracted successfully) \n",
      "Amazon URL 1: 24 items (extracted successfully) \n",
      "Amazon URL 2: 24 items (extracted successfully) \n",
      "Amazon URL 3: 24 items (extracted successfully) \n",
      "Amazon URL 4: 24 items (extracted successfully) \n",
      "Amazon URL 5: 3 items (extracted successfully) \n",
      "Amazon URL 6: 3 items (extracted successfully) \n",
      "Amazon URL 7: 2 items (extracted successfully) \n",
      "Amazon URL 8: 12 items (extracted successfully) \n",
      "Amazon URL 9: 3 items (extracted successfully) \n",
      "Amazon URL 10: 1 items (extracted successfully) \n",
      "Amazon URL 11: 9 items (extracted successfully) \n",
      "Amazon URL 12: 4 items (extracted successfully) \n",
      "Amazon URL 13: 3 items (extracted successfully) \n",
      "Amazon URL 14: 9 items (extracted successfully) \n",
      "Amazon URL 15: 18 items (extracted successfully) \n",
      "Amazon URL 16: 8 items (extracted successfully) \n",
      "Amazon URL 17: 24 items (extracted successfully) \n",
      "Amazon URL 18: 24 items (extracted successfully) \n",
      "Amazon URL 19: 1 items (extracted successfully) \n",
      "Amazon URL 20: 5 items (extracted successfully) \n",
      "Amazon URL 21: 4 items (extracted successfully) \n",
      "Amazon URL 22: 4 items (extracted successfully) \n",
      "Amazon URL 23: 8 items (extracted successfully) \n",
      "Amazon URL 24: 3 items (extracted successfully) \n",
      "Amazon URL 25: 24 items (extracted successfully) \n",
      "Amazon URL 26: 1 items (extracted successfully) \n",
      "Amazon URL 27: 16 items (extracted successfully) \n",
      "Amazon URL 28: 4 items (extracted successfully) \n",
      "Amazon URL 29: 24 items (extracted successfully) \n",
      "Amazon URL 30: 20 items (extracted successfully) \n",
      "Amazon URL 31: 24 items (extracted successfully) \n",
      "Amazon URL 32: 24 items (extracted successfully) \n",
      "Amazon URL 33: 24 items (extracted successfully) \n",
      "Amazon URL 34: 24 items (extracted successfully) \n",
      "Amazon URL 35: 24 items (extracted successfully) \n",
      "Amazon URL 36: 24 items (extracted successfully) \n",
      "Amazon URL 37: 24 items (extracted successfully) \n",
      "Amazon URL 38: 24 items (extracted successfully) \n",
      "Amazon URL 39: 24 items (extracted successfully) \n",
      "Amazon URL 40: 24 items (extracted successfully) \n",
      "Amazon URL 41: 24 items (extracted successfully) \n",
      "Amazon URL 42: 2 items (extracted successfully) \n",
      "Amazon URL 43: 24 items (extracted successfully) \n",
      "Amazon URL 44: 24 items (extracted successfully) \n",
      "Amazon URL 45: 24 items (extracted successfully) \n",
      "Amazon URL 46: 10 items (extracted successfully) \n",
      "Amazon URL 47: 24 items (extracted successfully) \n",
      "Amazon URL 48: 24 items (extracted successfully) \n",
      "Amazon URL 49: 24 items (extracted successfully) \n",
      "Amazon URL 50: 23 items (extracted successfully) \n",
      "Amazon URL 51: 24 items (extracted successfully) \n",
      "Extraction Successful. Number of Items: 824\n"
     ]
    }
   ],
   "source": [
    "# Iterated Extraction loop \n",
    "def iterative_extraction(amazon_links):\n",
    "    # Define constants\n",
    "    item_title_lst = []\n",
    "    item_tot = 0\n",
    "\n",
    "    # Extraction process\n",
    "    for i, link in enumerate(amazon_links): \n",
    "        # Extract the product titles from each link + take the size of each sequence\n",
    "        text_sequence = extract_labels(webdriver=driver, link=link)\n",
    "        seq_len = len(text_sequence)\n",
    "\n",
    "        # Store text sequence in list of all item titles\n",
    "        item_title_lst.append(text_sequence)\n",
    "        print(f\"Amazon URL {i}: {seq_len} items (extracted successfully) \")\n",
    "        item_tot += seq_len\n",
    "    print(f\"Extraction Successful. Number of Items: {item_tot}\")\n",
    "    \n",
    "    # Flatten all item titles\n",
    "    item_titles = np.array([item for title_seq in item_title_lst for item in title_seq])\n",
    "\n",
    "    return item_titles\n",
    "\n",
    "# Extract with full page\n",
    "full_page = amazon_ds[\"links\"].values\n",
    "label_list = iterative_extraction(amazon_links=full_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store label list\n",
    "label_ds = pd.DataFrame()\n",
    "label_ds[\"Labels\"] = label_list\n",
    "label_ds.to_csv(\"labels1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
